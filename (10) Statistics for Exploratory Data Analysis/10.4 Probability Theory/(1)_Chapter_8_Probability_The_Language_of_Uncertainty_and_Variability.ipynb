{
 "cells": [
  {
   "cell_type": "raw",
   "source": [
    "# Chapter 8: Probability - The Language of Uncertainty and Variability\n",
    "Chapter Eight is about probability theory and its applications in data analysis. The chapter covers the basic axioms and theorems of probability theory, as well as conditional probability and some common probability distributions.\n",
    "\n",
    "Probability theory is a branch of mathematics that deals with the study of random events and their outcomes. The basic axioms of probability theory include the additivity axiom, which states that the probability of the union of two events is equal to the sum of their individual probabilities, and the multiplication axiom, which states that the probability of the intersection of two events is equal to the product of their individual probabilities.\n",
    "\n",
    "Conditional probability is the probability of an event given that another event has already occurred. For example, the probability of a patient having a disease given that they have tested positive for the disease. Conditional probability is an important concept in many areas of data analysis, including Bayesian statistics.\n",
    "\n",
    "The chapter also covers some common probability distributions, such as the binomial distribution, the normal distribution, and the Poisson distribution. The Poisson distribution is particularly important in many areas of data analysis, such as in modeling the frequency of rare events.\n",
    "\n",
    "Spiegelhalter emphasizes the importance of understanding probability theory and its applications in data analysis. He provides helpful visualizations and examples to illustrate the concepts and shows how probability theory can be used to make inferences and predictions about real-world phenomena.\n",
    "\n",
    "Overall, Chapter Eight provides a comprehensive introduction to probability theory and its applications in data analysis. By understanding probability theory, we can better analyze and interpret data and make more informed ."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": ""
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Springboard Take Away Notes\n",
    "\n",
    "Many psychological experiments suggest that the concept of expected frequency assists our\n",
    "understanding of probability. Suppose we have an experiment at hand, such as flipping two\n",
    "coins in a row. Expected frequency is the concept we use when we ask ourselves: ‘What will\n",
    "happen if I try this experiment a number of times?’\n",
    "We can transform expected frequencies into probability trees. We can make a tree to illustrate\n",
    "the rules of probability.\n",
    "Conditional probability exists when a probability value of a given event depends on the outcome\n",
    "of other events. Two events are dependent if the probability of one depends on the outcome of\n",
    "the other.\n",
    "- This is a one-way relation. The prosecutor’s fallacy is a famous confusion here, and\n",
    "occurs when a small probability of the evidence, given innocence, is mistakenly\n",
    "interpreted as the probability of innocence, given the evidence.\n",
    "\n",
    "What is probability? Mathematicians and philosophers typically agree on the numbers but\n",
    "disagree on their meanings. There are various hypotheses:\n",
    "    I. classical interpretation: probability is the ratio of the number of outcomes favoring the event divided by the total number of possible, equally likely outcomes. (Problem: circular definition here: ‘equally likely’ seems to refer to probability).\n",
    "    II. enumerative interpretation: essentially a variant of option (I): probability is the ratio of\n",
    "    the number of outcomes favouring the event divided by the total enumerated set of\n",
    "    equally likely outcomes.\n",
    "    III. Long-run frequency interpretation: the probability of an event is the proportion of\n",
    "    times it occurs in an infinite sequence of relevantly similar experiments (Problem: most\n",
    "    situations cannot be translated into a repeatable experiment).\n",
    "    IV. Propensity or chance: probability is an objective property of events (Problem: this\n",
    "    property isn’t observable)\n",
    "    V. Subjective probability: probability is (or depends wholly on) a person’s subjective\n",
    "    judgements about likelihoods, and is roughly interpreted as betting odds (Problem: we\n",
    "    lose the impression of probability as an objective feature of the world, which it seems to\n",
    "    be).\n",
    "\n",
    "How do probability theory, data and learning about the target population relate to one another?\n",
    "- Probability comes into play when a data-point is considered to be generated by a\n",
    "randomizing device, like a coin flip or a pseudo-random-number generator.\n",
    "- Most of the time, we consider all the measurements available to us, which may have\n",
    "been collected informally or represent every possible observation. It remains useful to\n",
    "act as if these events were produced by some random process driven by probability. This\n",
    "is because an assumption of ‘chance’ captures all the inevitable unpredictability in the\n",
    "world (or what is called natural variability)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Chat GPT Elaborating on the takeaway notes\n",
    "\n",
    "In this passage, several key concepts related to probability are discussed, including expected frequency, conditional probability, and various interpretations of probability. Here, we'll elaborate on these concepts and their interconnections, as well as the relationship between probability theory, data, and learning about the target population.\n",
    "\n",
    "Expected frequency: This concept helps us predict the outcome of a repeated experiment. When we have an experiment, such as flipping two coins in a row, expected frequency can guide our understanding of what might happen if we perform the experiment multiple times.\n",
    "\n",
    "Probability trees: These are visual representations of the possible outcomes and probabilities in an experiment. By breaking down an experiment into its various steps and outcomes, a probability tree can help illustrate the rules of probability.\n",
    "\n",
    "Conditional probability: This is the probability of an event occurring, given that another event has already occurred. Events are considered dependent if the probability of one depends on the outcome of the other.\n",
    "\n",
    "Prosecutor's fallacy: This is a common error in reasoning where a small probability of evidence, given innocence, is mistakenly interpreted as the probability of innocence, given the evidence. This highlights the importance of understanding conditional probability and its implications correctly.\n",
    "\n",
    "Interpretations of probability: Different views on probability can lead to different interpretations of what probability represents. Some interpretations include the classical interpretation, enumerative interpretation, long-run frequency interpretation, propensity or chance interpretation, and subjective probability interpretation. Each interpretation has its own strengths and weaknesses.\n",
    "\n",
    "Now, let's explore the relationship between probability theory, data, and learning about the target population.\n",
    "\n",
    "Probability theory is a mathematical framework that helps us quantify uncertainty and make predictions based on the available data. In the context of studying a target population, probability theory can help us understand the patterns, trends, and relationships within the data.\n",
    "\n",
    "Data is a collection of measurements or observations that may come from various sources and be structured or unstructured. In order to draw conclusions about a target population, we analyze this data using probability theory and statistical methods.\n",
    "\n",
    "Learning about the target population involves using probability theory and data to make informed decisions or predictions. By assuming that events in the data are produced by some random process driven by probability, we can account for the natural variability and unpredictability of real-world events. This approach allows us to use probability theory to derive meaningful insights about the target population and make better decisions based on our understanding of the data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Expected Frequency - analogy\n",
    "\n",
    "Imagine you have a bag filled with differently colored marbles: 4 red marbles, 3 blue marbles, and 3 green marbles. You're going to pick one marble from the bag, observe its color, and then put it back in. The experiment consists of repeating this process multiple times.\n",
    "\n",
    "The expected frequency concept helps us understand the likelihood of picking a particular color after multiple trials. If you perform the experiment 10 times, you can expect to pick a red marble about 4 times, a blue marble about 3 times, and a green marble about 3 times, since there are 4 red, 3 blue, and 3 green marbles out of the total 10 marbles.\n",
    "\n",
    "It's important to note that this is an estimation based on probability; the actual outcome of 10 trials might vary. However, the more trials you perform, the closer your results will be to the expected frequency.\n",
    "\n",
    "In this analogy, expected frequency gives you an idea of what could happen after a certain number of trials (in this case, picking marbles from the bag). It's a way to visualize and predict the outcomes of repeated experiments based on the known probability of each event."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Probability Trees - Analogy\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://seeing-theory.brown.edu/basic-probability/index.html"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
