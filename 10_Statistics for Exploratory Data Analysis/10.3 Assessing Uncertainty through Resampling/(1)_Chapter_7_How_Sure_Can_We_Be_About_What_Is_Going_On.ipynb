{
 "cells": [
  {
   "cell_type": "raw",
   "source": [
    "##%%\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": ""
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Chapter 7: How Sure Can We Be About What Is Going On?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Summary\n",
    "\n",
    "Chapter Seven is about statistical inference, which is the process of drawing conclusions about a population based on a sample of data. The chapter covers core statistical concepts such as confidence intervals, margins of error, estimates, and bootstrapping.\n",
    "\n",
    "Confidence intervals are a way of estimating the range of values within which the true value of a population parameter is likely to fall. Margin of error is the amount by which a sample statistic might differ from the true population parameter. Estimates are calculated from sample data and used to make inferences about the population. Bootstrapping is a resampling method used to estimate the uncertainty of a sample statistic.\n",
    "\n",
    "The chapter also covers the use of statistical inference in hypothesis testing, where we test a hypothesis about a population parameter based on a sample of data. The process involves formulating a null hypothesis, which is then tested against an alternative hypothesis using a test statistic and a p-value. The p-value measures the strength of evidence against the null hypothesis, and a small p-value indicates that the evidence is unlikely to be due to chance.\n",
    "\n",
    "The chapter concludes with a discussion of the limitations of statistical inference and the importance of considering context and relevance when interpreting statistical results.\n",
    "\n",
    "Overall, Chapter Seven provides a solid foundation in statistical inference, which is an important tool for data analysis and decision-making."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Springboard Take Away Notes\n",
    "\n",
    "This **chapter** describes the various concepts of uncertainty that ought to be used when drawing conclusions with statistics and communicating those claims to others.\n",
    "When we take samples from a population about which we’d like to discover things, there will be variability in those samples. But if we have been prudent and avoided internal biases (for example by taking random samples) the summary statistics of the samples should be close to those of the study population.\n",
    "A margin of error is a plausible range in which a true feature of a population may lie, following a survey. A confidence interval, by contrast, is an estimated range within which an unknown parameter may plausibly lie. A confidence interval of 95% for a given value v gives a lower limit L and an upper limit U, and then entails that, before observing the data, there’s a 95% probability that the random interval (L, U) contains v.\n",
    "- The Central Limit Theorem is true: this is the claim that the sample mean of a set of random variables tends to have a normal sampling distribution, regardless of the shape of the underlying sampling distribution of the random variable.\n",
    "- Since The Central Limit Theorem is true, and close to 95% of a normal distribution lies between the mean +- 2 standard deviations, a common approximation for a 95% confidence interval is the estimate +- 2 standard errors.\n",
    "- The standard error of a sample mean is its standard deviation, when that sample mean is considered as a random variable.\n",
    "\n",
    "\n",
    "Bootstrapping is a means of generating confidence intervals and the distribution of test statistics by resampling the observed data with replacement, rather than by assuming a particular probability model for the underlying random variable.\n",
    "- ‘Bootstrapping’ has the name it does because we’re learning about the variability of an estimate without having to make any assumptions about the shape of the population distribution (or pulling ourselves up by our own bootstraps).\n",
    "- We bootstrap data when we do not want to make assumptions about the shape of the population.\n",
    "- Crucially, bootstrap distributions allow us to quantify our uncertainty about estimates. For example, we can find the range of values containing 95% of the means of the bootstrap resamples, and this can be a 95% uncertainty interval for the original estimates."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Confidence Intervals\n",
    "\n",
    "Suppose you are a fisherman trying to estimate the size of fish in a lake. You don't have the resources to catch every fish in the lake, so you take a random sample of fish and measure their size. Based on this sample, you want to estimate the average size of all the fish in the lake.\n",
    "\n",
    "However, you know that the size of fish in the lake can vary, so you want to account for this variability in your estimate. You decide to calculate a confidence interval, which is a range of values within which the true average size of fish is likely to fall.\n",
    "\n",
    "To calculate the confidence interval, you take your sample of fish and calculate the average size. Then, you use a statistical formula to calculate the margin of error, which is a measure of the amount by which your sample estimate might differ from the true average size of fish. Finally, you use the margin of error to construct a range of values, known as the confidence interval, within which you are confident the true average size of fish falls.\n",
    "\n",
    "For example, you might calculate a 95% confidence interval of 10-20 inches. This means that if you were to repeat the sampling process many times and calculate a 95% confidence interval each time, you would expect that 95% of the intervals would contain the true average size of fish in the lake.\n",
    "\n",
    "In summary, confidence intervals are like fishing nets that allow us to estimate the range of values within which the true population parameter is likely to fall, even though we can only observe a sample of the population."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Margins of Error\n",
    "\n",
    "Imagine you are an archer competing in a tournament. You want to hit the bullseye every time, but you know that your aim can vary from shot to shot. To account for this variability, you decide to measure the margin of error of your shots.\n",
    "\n",
    "To do this, you take several shots at the target and measure the distance between the center of each shot and the bullseye. Then, you calculate the average distance and use this as your estimate of your accuracy. However, you know that this estimate might not be exactly right, since your aim can vary from shot to shot.\n",
    "\n",
    "To measure the margin of error, you calculate the standard deviation of the distances between your shots and the bullseye. This gives you a measure of how much your aim can vary from shot to shot. The larger the standard deviation, the more variability in your aim, and the larger the margin of error.\n",
    "\n",
    "For example, if your average distance from the bullseye is 2 inches, and your standard deviation is 1 inch, then your margin of error might be ±1 inch. This means that you can be confident that your shots will fall within 1 inch of the bullseye, about 68% of the time.\n",
    "\n",
    "In summary, margins of error are like the range of possible distances between an archer's shots and the bullseye. They give us a measure of the variability in our estimates, and help us understand how much our estimate might differ from the true value."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Estimates\n",
    "\n",
    "An estimate is a calculated value based on sample data that is used to make inferences about the population. For example, if we want to estimate the average height of all individuals in a population, we can take a sample of individuals and calculate the average height of the sample. This calculated value is known as the sample mean and is an estimate of the population mean.\n",
    "\n",
    "It's important to note that estimates are not always perfectly accurate. They can be affected by random variability in the sample, sampling bias, or other factors. As a result, it's essential to understand the uncertainty associated with estimates and to quantify that uncertainty through the use of confidence intervals and margins of error.\n",
    "\n",
    "Spiegelhalter emphasizes the importance of using appropriate methods for estimating population parameters, such as using the appropriate estimator for the situation at hand. He also highlights the importance of reporting estimates accurately and transparently, including providing information about the sampling method and the level of uncertainty associated with the estimate.\n",
    "\n",
    "Overall, understanding the concept of estimates is crucial for making valid inferences about populations based on sample data. By using appropriate estimation methods and reporting estimates accurately, we can improve the reliability and validity of our statistical analyses.\n",
    "\n",
    "Imagine you are a teacher trying to estimate the average test score of all the students in your school. You can't test every student in the school, so you take a sample of students and give them a test. Based on this sample, you want to estimate the average test score of all the students in the school.\n",
    "\n",
    "To do this, you calculate the average test score of the students in your sample. This calculated value is known as the sample mean and is an estimate of the population mean. However, you know that your estimate might not be exactly right, since your sample might not be perfectly representative of the entire school population.\n",
    "\n",
    "To account for this uncertainty, you calculate a margin of error, which is a measure of the amount by which your sample estimate might differ from the true population parameter. The margin of error gives you a sense of the range of possible values for the true population parameter based on your sample.\n",
    "\n",
    "For example, you might calculate a sample mean of 80 and a margin of error of ±5. This means that you are confident that the true average test score of all the students in the school falls within the range of 75-85.\n",
    "\n",
    "In summary, estimates are like a teacher's estimate of the average test score of all the students in a school based on a sample of students. They give us a sense of the value of a population parameter based on sample data, but we need to be aware of the uncertainty associated with our estimate and use appropriate methods to quantify that uncertainty."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bootstrapping\n",
    "\n",
    "Bootstrapping is a resampling method used to estimate the uncertainty of a sample statistic, such as the sample mean or median. The idea behind bootstrapping is to simulate many additional samples from the original sample data, with replacement, and then calculate the statistic of interest for each simulated sample. By doing this, we can estimate the distribution of the statistic of interest and obtain a measure of uncertainty around the estimate.\n",
    "\n",
    "To perform bootstrapping, we start by taking a random sample of data from the population of interest. We then create many simulated samples by randomly selecting data points from the original sample with replacement. For each simulated sample, we calculate the statistic of interest, such as the sample mean or median. We repeat this process many times, creating a large number of simulated statistics.\n",
    "\n",
    "Using the simulated statistics, we can estimate the distribution of the statistic of interest and calculate confidence intervals to estimate the uncertainty around the estimate. The distribution of the simulated statistics can also provide valuable information about the shape of the population distribution, which can be useful in making further inferences.\n",
    "\n",
    "Bootstrapping is a useful technique when traditional methods of inference, such as normality assumptions, cannot be applied, or when the sample size is small. It allows us to estimate the uncertainty associated with our estimate and to perform more robust statistical inference.\n",
    "\n",
    "Overall, bootstrapping is a powerful tool for estimating the variability and uncertainty of sample statistics and can be useful in a wide range of statistical applications.\n",
    "\n",
    "Imagine you are a farmer trying to estimate the average weight of all the apples on your apple trees. You can't weigh every apple on every tree, so you take a sample of apples and weigh them. Based on this sample, you want to estimate the average weight of all the apples on your trees.\n",
    "\n",
    "To do this, you calculate the average weight of the apples in your sample. However, you know that your estimate might not be exactly right, since your sample might not be perfectly representative of all the apples on all the trees.\n",
    "\n",
    "To account for this uncertainty, you decide to use bootstrapping. You take your sample of apples and randomly select some of them with replacement, creating a simulated sample. You weigh the apples in the simulated sample and calculate the average weight. You repeat this process many times, creating a large number of simulated statistics.\n",
    "\n",
    "Using the simulated statistics, you can estimate the distribution of the average weight of apples on your trees and calculate confidence intervals to estimate the uncertainty around your estimate. The distribution of the simulated statistics can also provide valuable information about the variability of apple weights on different trees.\n",
    "\n",
    "In summary, bootstrapping is like a farmer simulating many different samples of apples by randomly selecting them with replacement from a small sample, and then using the simulated samples to estimate the distribution of the average weight of all the apples on their trees. By doing this, the farmer can obtain a measure of uncertainty around their estimate and make more robust inferences about the weight of all the apples on their trees."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
